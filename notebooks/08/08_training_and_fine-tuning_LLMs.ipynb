{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussamalafandi/Generative_AI/blob/main/notebooks/08/08_training_and_fine-tuning_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f170a6",
      "metadata": {
        "id": "05f170a6"
      },
      "source": [
        "# From Pre-training to Fine-tuning: Practical Guide for Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd4b8d7",
      "metadata": {
        "id": "9fd4b8d7"
      },
      "source": [
        "## Learning Objectives:\n",
        "\n",
        "By the end of this notebook, students will:\n",
        "\n",
        "* Understand the differences and purposes of pre-training, supervised fine-tuning (SFT), and preference-based training (DPO).\n",
        "* Be able to fine-tune small, efficient transformer models (SmolLM2-135M) on practical datasets.\n",
        "* Evaluate fine-tuned models quantitatively (perplexity/loss) and qualitatively (generation quality).\n",
        "* Get introduced to high-performance libraries (Unsloth) for efficient transformer fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1819a07",
      "metadata": {
        "id": "d1819a07"
      },
      "source": [
        "## Introduction and Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "644c1442",
      "metadata": {
        "id": "644c1442"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://images.ctfassets.net/kftzwdyauwt9/40in10B8KtAGrQvwRv5cop/8241bb17c283dced48ea034a41d7464a/chatgpt_diagram_light.png?w=2048&q=80&fm=webp\" alt=\"ChatGPT training phases\" width=\"1200\" />\n",
        "</div>\n",
        "\n",
        "Image source: [openai.com](https://openai.com/index/chatgpt/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51c7c937",
      "metadata": {
        "id": "51c7c937"
      },
      "source": [
        "### What is Pre-training?\n",
        "\n",
        "**Pre-training** is a process in which language models are initially trained on large-scale datasets using **self-supervised learning**. In simple terms, these models learn directly from the text itself without explicit labels provided by humans.\n",
        "\n",
        "Common pre-training tasks include:\n",
        "\n",
        "* **Causal Language Modeling (CLM):** Predicting the next word/token based on previous context.\n",
        "\n",
        "* **Masked Language Modeling (MLM):** Predicting hidden (masked) words in a sentence (e.g., used by BERT).\n",
        "\n",
        "Through pre-training, models capture fundamental language understanding, grammar, reasoning, and context comprehension. This general knowledge becomes the basis for further specialization through fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "868b80ab",
      "metadata": {
        "id": "868b80ab"
      },
      "source": [
        "#### SmolLM2 (Small and Efficient Model)\n",
        "\n",
        "In this course, we’ll use SmolLM2-135M, a compact and efficient transformer-based language model developed specifically to offer robust performance on modest hardware resources. SmolLM2 balances capability and efficiency, making it ideal for educational purposes, prototyping, and running on limited hardware (e.g., GPUs available via Colab)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628f28f8",
      "metadata": {
        "id": "628f28f8"
      },
      "source": [
        "### What is Supervised Fine-Tuning (SFT)?\n",
        "\n",
        "Although pre-trained models have broad language capabilities, they often lack task-specific accuracy. **Supervised Fine-Tuning (SFT)** bridges this gap, refining the general knowledge learned during pre-training by training the model further on task-specific data with explicit labels or prompts.\n",
        "\n",
        "Through fine-tuning, models become adept at specialized tasks, such as:\n",
        "\n",
        "* Conversational assistants\n",
        "* Text summarization\n",
        "* Sentiment analysis\n",
        "* Domain-specific language generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbeca4e5",
      "metadata": {
        "id": "cbeca4e5"
      },
      "source": [
        "#### SmolTalk Dataset\n",
        "\n",
        "In this notebook, we'll practically perform supervised fine-tuning using **SmolTalk**, a compact conversational dataset designed specifically for fine-tuning lightweight language models. SmolTalk is carefully crafted to provide realistic conversational exchanges, helping our SmolLM2 model improve significantly in generating natural dialogues and responding to instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30f76cdf",
      "metadata": {
        "id": "30f76cdf"
      },
      "source": [
        "### Preference-based Fine-tuning (DPO)\n",
        "\n",
        "Beyond supervised fine-tuning, recent approaches also incorporate **Preference-based Fine-tuning (DPO, Direct Preference Optimization)**. Instead of optimizing purely for task accuracy or next-token prediction, DPO fine-tunes models based on human-generated feedback indicating preference for specific responses.\n",
        "\n",
        "This method ensures models not only become task-specific but also align better with human preferences, improving their real-world usability, helpfulness, and alignment with ethical guidelines."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8943eee0",
      "metadata": {
        "id": "8943eee0"
      },
      "source": [
        "#### UltraFeedback Dataset (Introduction)\n",
        "\n",
        "Later in our course, we will explore DPO practically using the **UltraFeedback dataset**, which contains numerous examples of human preferences ranking model-generated outputs. UltraFeedback helps models like SmolLM2 adapt to human-preferred conversational styles and improves their ability to generate helpful, appropriate, and aligned responses."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f69a4987",
      "metadata": {
        "id": "f69a4987"
      },
      "source": [
        "\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/RvHjdlRT5gGQt5mJuhXH9.png\" alt=\"SmolLM2 Ecosystem\" width=\"1200\" />\n",
        "</div>\n",
        "\n",
        "Image source: [huggingface.co](https://huggingface.co/HuggingFaceTB)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d03d68b7",
      "metadata": {
        "id": "d03d68b7"
      },
      "source": [
        "## Load the [smoltalk](https://huggingface.co/datasets/HuggingFaceTB/smoltalk) Dataset\n",
        "\n",
        "In this notebook, we will load a subset of the `smoltalk` dataset. You can browse all available subsets [here](https://huggingface.co/datasets/HuggingFaceTB/smoltalk).  \n",
        "\n",
        "For our purposes, we will use the **`smoltalk-rewrite`** subset, which is designed for text rewriting tasks. This subset is ideal for training models focused on rewriting capabilities.  \n",
        "\n",
        "Feel free to experiment with other subsets to explore different tasks supported by the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b7c273e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7c273e2",
        "outputId": "ba43a5fb-4dd5-466d-e562-175eb905719e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': \"You're an AI assistant for text re-writing. Rewrite the input \"\n",
            "             'text to make it more concise while preserving its core meaning.',\n",
            "  'role': 'system'},\n",
            " {'content': 'Hey Alex,\\n'\n",
            "             '\\n'\n",
            "             \"I hope you're doing well! It's been a while since we met at the \"\n",
            "             'film festival last year. I was the one with the short film about '\n",
            "             \"the old abandoned factory. Anyway, I'm reaching out because I'm \"\n",
            "             'currently working on my thesis film project and I could really '\n",
            "             'use some advice on cinematography. I remember our conversation '\n",
            "             'about visual storytelling and I was hoping you might have some '\n",
            "             'tips or insights to share.\\n'\n",
            "             '\\n'\n",
            "             'My film is a drama set in a small town, and I want to capture '\n",
            "             'the mood and atmosphere of the location through my '\n",
            "             \"cinematography. I'm planning to shoot on location next month, \"\n",
            "             \"but I'm still trying to figure out the best way to approach it. \"\n",
            "             'If you have any suggestions or resources you could point me to, '\n",
            "             'I would be incredibly grateful.\\n'\n",
            "             '\\n'\n",
            "             \"Also, I heard from a mutual friend that you're having a \"\n",
            "             'photography exhibition soon. Congratulations! I would love to '\n",
            "             \"attend if you don't mind sending me the details.\\n\"\n",
            "             '\\n'\n",
            "             'Thanks in advance for any help you can provide. I really '\n",
            "             'appreciate it.\\n'\n",
            "             '\\n'\n",
            "             'Best,\\n'\n",
            "             'Jordan',\n",
            "  'role': 'user'},\n",
            " {'content': 'Hey Alex,\\n'\n",
            "             '\\n'\n",
            "             \"Hope you're well! It's Jordan from the film festival last year. \"\n",
            "             \"I'm working on my thesis film, a drama set in a small town, and \"\n",
            "             'could use your advice on cinematography to capture the mood and '\n",
            "             'atmosphere. Any tips or resources would be great.\\n'\n",
            "             '\\n'\n",
            "             \"Also, congrats on your upcoming photography exhibition! I'd love \"\n",
            "             'to attend; could you send me the details?\\n'\n",
            "             '\\n'\n",
            "             'Thanks a lot!\\n'\n",
            "             '\\n'\n",
            "             'Best,\\n'\n",
            "             'Jordan',\n",
            "  'role': 'assistant'}]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "\n",
        "train_dataset = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-rewrite\", split=\"train[:10%]\")\n",
        "eval_dataset = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-rewrite\", split=\"test[:10%]\")\n",
        "\n",
        "pprint(train_dataset[0]['messages'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "845d904f",
      "metadata": {
        "id": "845d904f"
      },
      "source": [
        "## Load the SmolLM2 Base Model and Tokenizer\n",
        "\n",
        "For supervised fine-tuning (SFT), we need to load the same tokenizer that was used to train the base model—SmolLM2.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8c81e241",
      "metadata": {
        "id": "8c81e241"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceTB/SmolLM2-135M\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "438d3469",
      "metadata": {},
      "source": [
        "In the next cell, we set a chat template to the tokenizer and adjust the model's embeddings to accomedate the newly introduced tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "746e7d98",
      "metadata": {},
      "outputs": [],
      "source": [
        "from trl import setup_chat_format\n",
        "\n",
        "model, tokenizer = setup_chat_format(model, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d9c80e5",
      "metadata": {
        "id": "6d9c80e5"
      },
      "source": [
        "The loaded dataset contains multi-turn conversations with clearly defined roles (e.g., user, assistant). Before passing this data to the language model, we need to format each conversation into a single coherent text sequence.\n",
        "\n",
        "This is where a **chat template** comes in—it defines the structure and formatting rules for representing conversations consistently. Many tokenizers support multiple chat templates, and you can choose one that best fits your use case. In this notebook, we use the template included with the `instruct` variant of the SmolLM2 tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f6be5c39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6be5c39",
        "outputId": "3ef1cc2b-5ca1-48c4-a7ee-ea6224496cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Formatted input with chat template:\n",
            " <|im_start|>system\n",
            "You're an AI assistant for text re-writing. Rewrite the input text to make it more concise while preserving its core meaning.<|im_end|>\n",
            "<|im_start|>user\n",
            "Hey Alex,\n",
            "\n",
            "I hope you're doing well! It's been a while since we met at the film festival last year. I was the one with the short film about the old abandoned factory. Anyway, I'm reaching out because I'm currently working on my thesis film project and I could really use some advice on cinematography. I remember our conversation about visual storytelling and I was hoping you might have some tips or insights to share.\n",
            "\n",
            "My film is a drama set in a small town, and I want to capture the mood and atmosphere of the location through my cinematography. I'm planning to shoot on location next month, but I'm still trying to figure out the best way to approach it. If you have any suggestions or resources you could point me to, I would be incredibly grateful.\n",
            "\n",
            "Also, I heard from a mutual friend that you're having a photography exhibition soon. Congratulations! I would love to attend if you don't mind sending me the details.\n",
            "\n",
            "Thanks in advance for any help you can provide. I really appreciate it.\n",
            "\n",
            "Best,\n",
            "Jordan<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Hey Alex,\n",
            "\n",
            "Hope you're well! It's Jordan from the film festival last year. I'm working on my thesis film, a drama set in a small town, and could use your advice on cinematography to capture the mood and atmosphere. Any tips or resources would be great.\n",
            "\n",
            "Also, congrats on your upcoming photography exhibition! I'd love to attend; could you send me the details?\n",
            "\n",
            "Thanks a lot!\n",
            "\n",
            "Best,\n",
            "Jordan<|im_end|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Using tokenizer's apply_chat_template method (if provided)\n",
        "# We'll format the example as an instruction-response pair\n",
        "chat_example = train_dataset[0]['messages']\n",
        "\n",
        "# Check the default chat template (optional, but useful for inspection)\n",
        "formatted_input = tokenizer.apply_chat_template(chat_example, tokenize=False)\n",
        "print(\"\\nFormatted input with chat template:\\n\", formatted_input)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d9e85d",
      "metadata": {
        "id": "d5d9e85d"
      },
      "source": [
        "## Apply Chat Template and Tokenize the Dataset\n",
        "\n",
        "Next, we'll tokenize the dataset using the selected chat template. To do this, we'll define a tokenization function and apply it across the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7d348eb5",
      "metadata": {
        "id": "7d348eb5",
        "outputId": "906778ae-0444-4177-d680-897a022a4abb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1dbed2b832e4faf8a38971afcf615ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5334 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def tokenize_with_chat_template(example):\n",
        "    # Use the tokenizer's apply_chat_template method to format the input\n",
        "    formatted_input = tokenizer.apply_chat_template(example['messages'], tokenize=False)\n",
        "\n",
        "    # Tokenize the formatted input\n",
        "    tokenized_input = tokenizer(formatted_input, truncation=True)\n",
        "\n",
        "    return tokenized_input\n",
        "\n",
        "# Tokenize the entire dataset using the custom function\n",
        "tokenized_dataset = train_dataset.map(\n",
        "    tokenize_with_chat_template,\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset.column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "35fbdf6d",
      "metadata": {
        "id": "35fbdf6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Decoded sample:\n",
            " <|im_start|>system\n",
            "You're an AI assistant for text re-writing. Rewrite the input text to make it more concise while preserving its core meaning.<|im_end|>\n",
            "<|im_start|>user\n",
            "Hey Alex,\n",
            "\n",
            "I hope you're doing well! It's been a while since we met at the film festival last year. I was the one with the short film about the old abandoned factory. Anyway, I'm reaching out because I'm currently working on my thesis film project and I could really use some advice on cinematography. I remember our conversation about visual storytelling and I was hoping you might have some tips or insights to share.\n",
            "\n",
            "My film is a drama set in a small town, and I want to capture the mood and atmosphere of the location through my cinematography. I'm planning to shoot on location next month, but I'm still trying to figure out the best way to approach it. If you have any suggestions or resources you could point me to, I would be incredibly grateful.\n",
            "\n",
            "Also, I heard from a mutual friend that you're having a photography exhibition soon. Congratulations! I would love to attend if you don't mind sending me the details.\n",
            "\n",
            "Thanks in advance for any help you can provide. I really appreciate it.\n",
            "\n",
            "Best,\n",
            "Jordan<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Hey Alex,\n",
            "\n",
            "Hope you're well! It's Jordan from the film festival last year. I'm working on my thesis film, a drama set in a small town, and could use your advice on cinematography to capture the mood and atmosphere. Any tips or resources would be great.\n",
            "\n",
            "Also, congrats on your upcoming photography exhibition! I'd love to attend; could you send me the details?\n",
            "\n",
            "Thanks a lot!\n",
            "\n",
            "Best,\n",
            "Jordan<|im_end|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Decode back for sanity check\n",
        "decoded_sample = tokenizer.decode(tokenized_dataset[0]['input_ids'])\n",
        "print(\"\\nDecoded sample:\\n\", decoded_sample)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "396fba7d",
      "metadata": {},
      "source": [
        "## Configure and Initialize the Trainer\n",
        "\n",
        "With our model and tokenized dataset ready, we can now configure the training setup.  \n",
        "We'll use `SFTTrainer` from the `trl` library to handle supervised fine-tuning (SFT).  \n",
        "Below, we define the training arguments and initialize the trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f70b9ee",
      "metadata": {
        "id": "3f70b9ee"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "training_args = SFTConfig(\n",
        "    output_dir=\"./smollm2-sft-results\",   # Output directory for model checkpoints\n",
        "    num_train_epochs=3,                   # Number of epochs\n",
        "    learning_rate=3e-5,                   # Learning rate # try with 5e-5\n",
        "    logging_steps=10,                     # How often to log training progress\n",
        "    save_steps=100,                       # How often to save checkpoints\n",
        "    per_device_train_batch_size=4,        # Set according to your GPU memory capacity\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"steps\",                # Evaluate the model at regular intervals\n",
        "    eval_steps=50,                        # Frequency of evaluation\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4da680f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "4da680f6",
        "outputId": "cc5b33f0-a848-49de-cdc4-7a567713ee1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='251' max='40008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  251/40008 14:34 < 38:47:25, 0.28 it/s, Epoch 0.02/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.978800</td>\n",
              "      <td>1.319638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.197300</td>\n",
              "      <td>1.244419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.180600</td>\n",
              "      <td>1.215166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.174200</td>\n",
              "      <td>1.196922</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='314' max='351' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [314/351 02:27 < 00:17, 2.12 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd3d5f9c",
      "metadata": {},
      "source": [
        "## Evaluate the Model\n",
        "\n",
        "After training, we can evaluate our fine-tuned model by providing it with input messages from the evaluation dataset.  \n",
        "We can then compare its responses to those generated by the base model to assess improvements in performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "465aab03",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Decoded output:\n",
            " <|im_start|>system\n",
            "You're an AI assistant for text re-writing. Rewrite the input text to make it more concise while preserving its core meaning.<|im_end|>\n",
            "<|im_start|>user\n",
            "Hey Alex,\n",
            "\n",
            "I hope you're doing well! It's been a while since we met at the film festival last year. I was the one with the short film about the old abandoned factory. Anyway, I'm reaching out because I'm currently working on my thesis film project and I could really use some advice on cinematography. I remember our conversation about visual storytelling and I was hoping you might have some tips or insights to share.\n",
            "\n",
            "My film is a drama set in a small town, and I want to capture the mood and atmosphere of the location through my cinematography. I'm planning to shoot on location next month, but I'm still trying to figure out the best way to approach it. If you have any suggestions or resources you could point me to, I would be incredibly grateful.\n",
            "\n",
            "Also, I heard from a mutual friend that you're having a photography exhibition soon. Congratulations! I would love to attend if you don't mind sending me the details.\n",
            "\n",
            "Thanks in advance for any help you can provide. I really appreciate it.\n",
            "\n",
            "Best,\n",
            "Jordan<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Hey Alex,\n",
            "\n",
            "Hope you're well! I'm working on my thesis about the abandoned factory and I need some advice on cinematography. I remember our discussion on visual storytelling, and I was thinking about shooting on location next month, but I'm still trying to figure out how to approach it. Any tips or resources you could share would be super helpful.\n",
            "\n",
            "Also, I heard you're having a photography exhibition soon. Congratulations! I'll be there if you're willing to send me the details.\n",
            "\n",
            "Thanks a ton!\n",
            "\n",
            "Best,\n",
            "Jordan<|im_end|>\n",
            "<|im_end|>assistant\n",
            "Hey Alex,\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"hussamalafandi/smollm2-sft-rewrite\", device_map=\"auto\") # change to \"HuggingFaceTB/SmolLM2-135M\" to compare with the base model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"hussamalafandi/smollm2-sft-rewrite\", device_map=\"auto\")\n",
        "\n",
        "prompt = [{'content': \"You're an AI assistant for text re-writing. Rewrite the input \"\n",
        "             'text to make it more concise while preserving its core meaning.',\n",
        "  'role': 'system'},\n",
        " {'content': 'Hey Alex,\\n'\n",
        "             '\\n'\n",
        "             \"I hope you're doing well! It's been a while since we met at the \"\n",
        "             'film festival last year. I was the one with the short film about '\n",
        "             \"the old abandoned factory. Anyway, I'm reaching out because I'm \"\n",
        "             'currently working on my thesis film project and I could really '\n",
        "             'use some advice on cinematography. I remember our conversation '\n",
        "             'about visual storytelling and I was hoping you might have some '\n",
        "             'tips or insights to share.\\n'\n",
        "             '\\n'\n",
        "             'My film is a drama set in a small town, and I want to capture '\n",
        "             'the mood and atmosphere of the location through my '\n",
        "             \"cinematography. I'm planning to shoot on location next month, \"\n",
        "             \"but I'm still trying to figure out the best way to approach it. \"\n",
        "             'If you have any suggestions or resources you could point me to, '\n",
        "             'I would be incredibly grateful.\\n'\n",
        "             '\\n'\n",
        "             \"Also, I heard from a mutual friend that you're having a \"\n",
        "             'photography exhibition soon. Congratulations! I would love to '\n",
        "             \"attend if you don't mind sending me the details.\\n\"\n",
        "             '\\n'\n",
        "             'Thanks in advance for any help you can provide. I really '\n",
        "             'appreciate it.\\n'\n",
        "             '\\n'\n",
        "             'Best,\\n'\n",
        "             'Jordan',\n",
        "  'role': 'user'}]\n",
        "\n",
        "chat_template_prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "tokenized_prompt = tokenizer(chat_template_prompt, return_tensors=\"pt\")\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids=tokenized_prompt['input_ids'].to(\"cuda\"),\n",
        "    attention_mask=tokenized_prompt['attention_mask'].to(\"cuda\"),\n",
        "    max_new_tokens=128,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=50,\n",
        "    num_return_sequences=1,\n",
        ")\n",
        "decoded_output = tokenizer.decode(output[0])\n",
        "\n",
        "print(\"\\nDecoded output:\\n\", decoded_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93294cd5",
      "metadata": {},
      "source": [
        "### Using a Pipeline\n",
        "\n",
        "Instead of loading the model and tokenizer separately, you can streamline the process by using the `pipeline` utility from the Hugging Face Transformers library.\n",
        "\n",
        "The typical steps—applying a chat template to your prompt, tokenizing the input, passing it through the model, and decoding the output—are handled internally by the pipeline. This simplifies your workflow and reduces the potential for errors.\n",
        "\n",
        "> **Note:** This approach only works if your trained model is compatible with the Hugging Face Transformers library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "090e1795",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hey Alex,\n",
            "\n",
            "Hope you're well! I'm working on a thesis film and need some advice on cinematography. I remember our conversation about visual storytelling and want to shoot on location next month. Any tips or resources would be great.\n",
            "\n",
            "Also, I heard from a mutual friend that you're having an exhibition next month. Congratulations! I'll be there.\n",
            "\n",
            "Thanks a lot!\n",
            "\n",
            "Best,\n",
            "Jordan\n",
            "assistant\n",
            "Hey Alex,\n",
            "\n",
            "Hope you're well! I'm working on a thesis film and need some advice on cinematography. I remember our conversation about visual storytelling\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "prompt = [\n",
        "    {'content': \"You're an AI assistant for text re-writing. Rewrite the input \"\n",
        "     'text to make it more concise while preserving its core meaning.',\n",
        "     'role': 'system'},\n",
        "\n",
        "    {'content': 'Hey Alex,\\n'\n",
        "     '\\n'\n",
        "     \"I hope you're doing well! It's been a while since we met at the \"\n",
        "     'film festival last year. I was the one with the short film about '\n",
        "     \"the old abandoned factory. Anyway, I'm reaching out because I'm \"\n",
        "     'currently working on my thesis film project and I could really '\n",
        "     'use some advice on cinematography. I remember our conversation '\n",
        "     'about visual storytelling and I was hoping you might have some '\n",
        "     'tips or insights to share.\\n'\n",
        "     '\\n'\n",
        "     'My film is a drama set in a small town, and I want to capture '\n",
        "     'the mood and atmosphere of the location through my '\n",
        "     \"cinematography. I'm planning to shoot on location next month, \"\n",
        "     \"but I'm still trying to figure out the best way to approach it. \"\n",
        "     'If you have any suggestions or resources you could point me to, '\n",
        "     'I would be incredibly grateful.\\n'\n",
        "     '\\n'\n",
        "     \"Also, I heard from a mutual friend that you're having a \"\n",
        "     'photography exhibition soon. Congratulations! I would love to '\n",
        "     \"attend if you don't mind sending me the details.\\n\"\n",
        "     '\\n'\n",
        "     'Thanks in advance for any help you can provide. I really '\n",
        "     'appreciate it.\\n'\n",
        "     '\\n'\n",
        "     'Best,\\n'\n",
        "     'Jordan',\n",
        "     'role': 'user'}]\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"hussamalafandi/smollm2-sft-rewrite\", device=\"cuda\")\n",
        "\n",
        "output = generator(prompt, max_new_tokens=128, return_full_text=False)[0]\n",
        "print(output[\"generated_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad1a13b7",
      "metadata": {},
      "source": [
        "# Resources\n",
        "\n",
        "[HuggingFace LLM Course](https://huggingface.co/learn/llm-course)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
